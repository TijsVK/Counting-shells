
@article{s22145286,
  author         = {Hassen, Khouloud Ben Ali and Machado, José J. M. and Tavares, João Manuel R. S.},
  title          = {Convolutional Neural Networks and Heuristic Methods for Crowd Counting: A Systematic Review},
  journal        = {Sensors},
  volume         = {22},
  year           = {2022},
  number         = {14},
  article-number = {5286},
  url            = {https://www.mdpi.com/1424-8220/22/14/5286},
  pubmedid       = {35890966},
  issn           = {1424-8220},
  abstract       = {The crowd counting task has become a pillar for crowd control as it provides information concerning the number of people in a scene. It is helpful in many scenarios such as video surveillance, public safety, and future event planning. To solve such tasks, researchers have proposed different solutions. In the beginning, researchers went with more traditional solutions, while recently the focus is on deep learning methods and, more specifically, on Convolutional Neural Networks (CNNs), because of their efficiency. This review explores these methods by focusing on their key differences, advantages, and disadvantages. We have systematically analyzed algorithms and works based on the different models suggested and the problems they are trying to solve. The main focus is on the shift made in the history of crowd counting methods, moving from the heuristic models to CNN models by identifying each category and discussing its different methods and architectures. After a deep study of the literature on crowd counting, the survey partitions current datasets into sparse and crowded ones. It discusses the reviewed methods by comparing their results on the different datasets. The findings suggest that the heuristic models could be even more effective than the CNN models in sparse scenarios.},
  doi            = {10.3390/s22145286}
}

@article{aaai08-132,
  author   = {Chang, M-W and Ratinov, L and Roth, D and Srikumar, V},
  title    = {Importance of Semantic Representation: Dataless Classification},
  journal  = {Importance of semantic representation: Dataless classification},
  year     = {2008},
  url      = {https://www.aaai.org/Library/AAAI/2008/aaai08-132.php},
  abstract = {Traditionally, text categorization has been studied as the problem of training of a classifier using labeled data. However, people can categorize documents into named categories without any explicit training because we know the meaning of category names. In this paper, we introduce Dataless Classification, a learning protocol that uses world knowledge to induce classifiers without the need for any labeled data. Like humans, a dataless classifier interprets a string of words as a set of semantic concepts. We propose a model for dataless classification and show that the label name alone is often sufficient to induce classifiers. Using Wikipedia as our source of world knowledge, we get 85.29% accuracy on tasks from the 20 Newsgroup dataset and 88.62% accuracy on tasks from a Yahoo! Answers dataset without any labeled or unlabeled data from the datasets. With unlabeled data, we can further improve the results and show quite competitive performance to a supervised learning algorithm that uses 100 labeled examples.}
}

%Biederman I. (1987). Recognition-by-components: a theory of human image understanding. Psychological review, 94(2), 115–147. https://doi.org/10.1037/0033-295X.94.2.115

@article{biederman1987recognition,
  title     = {Recognition-by-components: a theory of human image understanding},
  author    = {Biederman, Irving},
  journal   = {Psychological review},
  volume    = {94},
  number    = {2},
  pages     = {115--147},
  year      = {1987},
  publisher = {American Psychological Association},
  url       = {https://doi.org/10.1037/0033-295X.94.2.115},
  abstract  = {The perceptual recognition of objects is conceptualized to be a process in which the image of the input is segmented at regions of deep concavity into an arrangement of simple geometric components. The fundamental assumption of the proposed theory, recognition-by-components (RBC), is that a modest set of generalized-cone components, called geons, can be derived from contrasts of five readily detectable properties of edges in a two-dimensional image. The detection of these properties is generally invariant over viewing position and image quality and consequently allows robust object perception when the image is projected from a novel viewpoint or is degraded. RBC thus provides a principled account of the heretofore undecided relation between the classic principles of perceptual organization and pattern recognition. The results from experiments on the perception of briefly presented pictures by human observers provide empirical support for the theory.}
}


@inproceedings{FSFSOD,
  title     = {Frustratingly Simple Few-Shot Object Detection},
  author    = {Wang, Xin and Huang, Thomas and Gonzalez, Joseph and Darrell, Trevor and Yu, Fisher},
  booktitle = {Proceedings of the 37th International Conference on Machine Learning},
  pages     = {9919--9928},
  year      = {2020},
  editor    = {III, Hal Daumé and Singh, Aarti},
  volume    = {119},
  series    = {Proceedings of Machine Learning Research},
  month     = {13--18 Jul},
  publisher = {PMLR},
  pdf       = {http://proceedings.mlr.press/v119/wang20j/wang20j.pdf},
  url       = {https://proceedings.mlr.press/v119/wang20j.html},
  abstract  = {Detecting rare objects from a few examples is an emerging problem. Prior works show meta-learning is a promising approach. But, fine-tuning techniques have drawn scant attention. We find that fine-tuning only the last layer of existing detectors on rare classes is crucial to the few-shot object detection task. Such a simple approach outperforms the meta-learning methods by roughly 2&nbsp;20 points on current benchmarks and sometimes even doubles the accuracy of the prior methods. However, the high variance in the few samples often leads to the unreliability of existing benchmarks. We revise the evaluation protocols by sampling multiple groups of training examples to obtain stable comparisons and build new benchmarks based on three datasets: PASCAL VOC, COCO and LVIS. Again, our fine-tuning approach establishes a new state of the art on the revised benchmarks. The code as well as the pretrained models are available at https://github.com/ucbdrive/few-shot-object-detection.}
}

@article{DBLP:journals/corr/abs-2011-10142,
  author     = {Weilin Zhang and
                Yu{-}Xiong Wang and
                David A. Forsyth},
  title      = {Cooperating RPN's Improve Few-Shot Object Detection},
  journal    = {CoRR},
  volume     = {abs/2011.10142},
  year       = {2020},
  url        = {https://arxiv.org/abs/2011.10142},
  eprinttype = {arXiv},
  eprint     = {2011.10142},
  timestamp  = {Wed, 25 Nov 2020 16:34:14 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2011-10142.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{VU2022104398,
  title    = {Few-shot object detection via baby learning},
  journal  = {Image and Vision Computing},
  volume   = {120},
  pages    = {104398},
  year     = {2022},
  issn     = {0262-8856},
  doi      = {https://doi.org/10.1016/j.imavis.2022.104398},
  url      = {https://www.sciencedirect.com/science/article/pii/S0262885622000270},
  author   = {Anh-Khoa Nguyen Vu and Nhat-Duy Nguyen and Khanh-Duy Nguyen and Vinh-Tiep Nguyen and Thanh Duc Ngo and Thanh-Toan Do and Tam V. Nguyen},
  keywords = {Few-shot object detection, Few-shot learning, Baby learning},
  abstract = {Few-shot learning is proposed to overcome the problem of scarce training data in novel classes. Recently, few-shot learning has been well adopted in various computer vision tasks such as object recognition and object detection. However, the state-of-the-art (SOTA) methods have less attention to effectively reuse the information from previous stages. In this paper, we propose a new framework of few-shot learning for object detection. In particular, we adopt Baby Learning mechanism along with the multiple receptive fields to effectively utilize the former knowledge in novel domain. The propoed framework imitates the learning process of a baby through visual cues. The extensive experiments demonstrate the superiority of the proposed method over the SOTA methods on the benchmarks (improve average 7.0% on PASCAL VOC and 1.6% on MS COCO).}
}

@article{DBLP:journals/corr/abs-2105-09491,
  author     = {Zhibo Fan and
                Yuchen Ma and
                Zeming Li and
                Jian Sun},
  title      = {Generalized Few-Shot Object Detection without Forgetting},
  journal    = {CoRR},
  volume     = {abs/2105.09491},
  year       = {2021},
  url        = {https://arxiv.org/abs/2105.09491},
  eprinttype = {arXiv},
  eprint     = {2105.09491},
  timestamp  = {Tue, 31 Aug 2021 13:57:12 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2105-09491.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DBLP:journals/corr/abs-2103-05950,
  author     = {Bo Sun and
                Banghuai Li and
                Shengcai Cai and
                Ye Yuan and
                Chi Zhang},
  title      = {{FSCE:} Few-Shot Object Detection via Contrastive Proposal Encoding},
  journal    = {CoRR},
  volume     = {abs/2103.05950},
  year       = {2021},
  url        = {https://arxiv.org/abs/2103.05950},
  eprinttype = {arXiv},
  eprint     = {2103.05950},
  timestamp  = {Tue, 16 Mar 2021 11:26:59 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2103-05950.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{rs14143255,
  author         = {Wang, Yan and Xu, Chaofei and Liu, Cuiwei and Li, Zhaokui},
  title          = {Context Information Refinement for Few-Shot Object Detection in Remote Sensing Images},
  journal        = {Remote Sensing},
  volume         = {14},
  year           = {2022},
  number         = {14},
  article-number = {3255},
  url            = {https://www.mdpi.com/2072-4292/14/14/3255},
  issn           = {2072-4292},
  abstract       = {Recently, few-shot object detection based on fine-tuning has attracted much attention in the field of computer vision. However, due to the scarcity of samples in novel categories, obtaining positive anchors for novel categories is difficult, which implicitly introduces the foreground&ndash;background imbalance problem. It is difficult to identify foreground objects from complex backgrounds due to various object sizes and cluttered backgrounds. In this article, we propose a novel context information refinement few-shot detector (CIR-FSD) for remote sensing images. In particular, we design a context information refinement (CIR) module to extract discriminant context features. This module uses dilated convolutions and dense connections to capture rich context information from different receptive fields and then uses a binary map as the supervision label to refine the context information. In addition, we improve the region proposal network (RPN). Concretely, the RPN is fine-tuned on novel categories, and the constraint of non-maximum suppression (NMS) is relaxed, which can obtain more positive anchors for novel categories. Experiments on two remote sensing public datasets show the effectiveness of our detector.},
  doi            = {10.3390/rs14143255}
}

@article{few-shot-comprehensive-survey,
  author     = {Mona K{\"{o}}hler and
                Markus Eisenbach and
                Horst{-}Michael Gross},
  title      = {Few-Shot Object Detection: {A} Survey},
  journal    = {CoRR},
  volume     = {abs/2112.11699},
  year       = {2021},
  url        = {https://arxiv.org/abs/2112.11699},
  eprinttype = {arXiv},
  eprint     = {2112.11699},
  timestamp  = {Tue, 04 Jan 2022 15:59:27 +0100},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2112-11699.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{fasterrcnn,
  author     = {Shaoqing Ren and
                Kaiming He and
                Ross B. Girshick and
                Jian Sun},
  title      = {Faster {R-CNN:} Towards Real-Time Object Detection with Region Proposal
                Networks},
  journal    = {CoRR},
  volume     = {abs/1506.01497},
  year       = {2015},
  url        = {http://arxiv.org/abs/1506.01497},
  eprinttype = {arXiv},
  eprint     = {1506.01497},
  timestamp  = {Mon, 13 Aug 2018 16:46:02 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/RenHG015.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{fastrcnn,
  author     = {Ross B. Girshick},
  title      = {Fast {R-CNN}},
  journal    = {CoRR},
  volume     = {abs/1504.08083},
  year       = {2015},
  url        = {http://arxiv.org/abs/1504.08083},
  eprinttype = {arXiv},
  eprint     = {1504.08083},
  timestamp  = {Mon, 13 Aug 2018 16:49:11 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/Girshick15.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{LSTD,
  author     = {Hao Chen and
                Yali Wang and
                Guoyou Wang and
                Yu Qiao},
  title      = {{LSTD:} {A} Low-Shot Transfer Detector for Object Detection},
  journal    = {CoRR},
  volume     = {abs/1803.01529},
  year       = {2018},
  url        = {http://arxiv.org/abs/1803.01529},
  eprinttype = {arXiv},
  eprint     = {1803.01529},
  timestamp  = {Sat, 06 Aug 2022 22:05:45 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-1803-01529.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{DeFRCN,
  author     = {Limeng Qiao and
                Yuxuan Zhao and
                Zhiyuan Li and
                Xi Qiu and
                Jianan Wu and
                Chi Zhang},
  title      = {DeFRCN: Decoupled Faster {R-CNN} for Few-Shot Object Detection},
  journal    = {CoRR},
  volume     = {abs/2108.09017},
  year       = {2021},
  url        = {https://arxiv.org/abs/2108.09017},
  eprinttype = {arXiv},
  eprint     = {2108.09017},
  timestamp  = {Mon, 23 Aug 2021 14:07:13 +0200},
  biburl     = {https://dblp.org/rec/journals/corr/abs-2108-09017.bib},
  bibsource  = {dblp computer science bibliography, https://dblp.org}
}

@article{MetaDETR,
  author  = {Zhang, Gongjie and Luo, Zhipeng and Cui, Kaiwen and Lu, Shijian and Xing, Eric P.},
  journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title   = {Meta-DETR: Image-Level Few-Shot Detection with Inter-Class Correlation Exploitation},
  year    = {2022},
  volume  = {},
  number  = {},
  pages   = {1-12},
  doi     = {10.1109/TPAMI.2022.3195735}
}

@article{meta-rcnn,
  author    = {Xiaopeng Yan and
               Ziliang Chen and
               Anni Xu and
               Xiaoxi Wang and
               Xiaodan Liang and
               Liang Lin},
  title     = {Meta {R-CNN} : Towards General Solver for Instance-level Low-shot
               Learning},
  journal   = {CoRR},
  volume    = {abs/1909.13032},
  year      = {2019},
  url       = {http://arxiv.org/abs/1909.13032},
  eprinttype = {arXiv},
  eprint    = {1909.13032},
  timestamp = {Wed, 02 Oct 2019 13:04:08 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1909-13032.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{maskrcnn,
  author    = {Kaiming He and
               Georgia Gkioxari and
               Piotr Doll{\'{a}}r and
               Ross B. Girshick},
  title     = {Mask {R-CNN}},
  journal   = {CoRR},
  volume    = {abs/1703.06870},
  year      = {2017},
  url       = {http://arxiv.org/abs/1703.06870},
  eprinttype = {arXiv},
  eprint    = {1703.06870},
  timestamp = {Mon, 13 Aug 2018 16:46:36 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/HeGDG17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{Kustportaal,
  author = {Kustportaal},
  title = {Toerisme en recreatie},
  year = {2021},
  url = {https://www.kustportaal.be/nl/toerisme-en-recreatie#:~:text=De%20Belgische%20kust%20is%20de,in%20totaal%2027.723.420%20overnachtingen},
  note = {Accessed 8 Jan 2023}
}

@InProceedings{Shanghaitech,
author = {Zhang, Yingying and Zhou, Desen and Chen, Siqin and Gao, Shenghua and Ma, Yi},
title = {Single-Image Crowd Counting via Multi-Column Convolutional Neural Network},
booktitle = {Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR)},
month = {June},
year = {2016}
}

@article{COWC,
  author    = {T. Nathan Mundhenk and
               Goran Konjevod and
               Wesam A. Sakla and
               Kofi Boakye},
  title     = {A Large Contextual Dataset for Classification, Detection and Counting
               of Cars with Deep Learning},
  journal   = {CoRR},
  volume    = {abs/1609.04453},
  year      = {2016},
  url       = {http://arxiv.org/abs/1609.04453},
  eprinttype = {arXiv},
  eprint    = {1609.04453},
  timestamp = {Mon, 13 Aug 2018 16:45:57 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/MundhenkKSB16.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@article{One-shot-siamese,
  author    = {Claudio Michaelis and
               Ivan Ustyuzhaninov and
               Matthias Bethge and
               Alexander S. Ecker},
  title     = {One-Shot Instance Segmentation},
  journal   = {CoRR},
  volume    = {abs/1811.11507},
  year      = {2018},
  url       = {http://arxiv.org/abs/1811.11507},
  eprinttype = {arXiv},
  eprint    = {1811.11507},
  timestamp = {Thu, 14 Oct 2021 09:15:21 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/abs-1811-11507.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{COCO,
      title={Microsoft COCO: Common Objects in Context}, 
      author={Tsung-Yi Lin and Michael Maire and Serge Belongie and Lubomir Bourdev and Ross Girshick and James Hays and Pietro Perona and Deva Ramanan and C. Lawrence Zitnick and Piotr Dollár},
      year={2015},
      eprint={1405.0312},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{owlvit,
      title={Simple Open-Vocabulary Object Detection with Vision Transformers}, 
      author={Matthias Minderer and Alexey Gritsenko and Austin Stone and Maxim Neumann and Dirk Weissenborn and Alexey Dosovitskiy and Aravindh Mahendran and Anurag Arnab and Mostafa Dehghani and Zhuoran Shen and Xiao Wang and Xiaohua Zhai and Thomas Kipf and Neil Houlsby},
      year={2022},
      eprint={2205.06230},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{imTED,
      title={Integrally Migrating Pre-trained Transformer Encoder-decoders for Visual Object Detection}, 
      author={Feng Liu and Xiaosong Zhang and Zhiliang Peng and Zonghao Guo and Fang Wan and Xiangyang Ji and Qixiang Ye},
      year={2022},
      eprint={2205.09613},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@misc{hANMCL,
      title={Hierarchical Attention Network for Few-Shot Object Detection via Meta-Contrastive Learning}, 
      author={Dongwoo Park and Jong-Min Lee},
      year={2022},
      eprint={2208.07039},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@article{rcnn,
  author       = {Ross B. Girshick and
                  Jeff Donahue and
                  Trevor Darrell and
                  Jitendra Malik},
  title        = {Rich feature hierarchies for accurate object detection and semantic
                  segmentation},
  journal      = {CoRR},
  volume       = {abs/1311.2524},
  year         = {2013},
  url          = {http://arxiv.org/abs/1311.2524},
  eprinttype    = {arXiv},
  eprint       = {1311.2524},
  timestamp    = {Mon, 13 Aug 2018 16:48:09 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/GirshickDDM13.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@Article{selectivesearch,
  author       = "Uijlings, J. R. R. and van de Sande, K. E. A. and Gevers, T. and Smeulders, A. W. M.",
  title        = "Selective Search for Object Recognition",
  journal      = "International Journal of Computer Vision",
  number       = "2",
  volume       = "104",
  pages        = "154--171",
  year         = "2013",
  url          = "https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013",
  pdf          = "https://ivi.fnwi.uva.nl/isis/publications/2013/UijlingsIJCV2013/UijlingsIJCV2013.pdf",
  has_image    = 1
}

@article{sppnet,
  author       = {Kaiming He and
                  Xiangyu Zhang and
                  Shaoqing Ren and
                  Jian Sun},
  title        = {Spatial Pyramid Pooling in Deep Convolutional Networks for Visual
                  Recognition},
  journal      = {CoRR},
  volume       = {abs/1406.4729},
  year         = {2014},
  url          = {http://arxiv.org/abs/1406.4729},
  eprinttype    = {arXiv},
  eprint       = {1406.4729},
  timestamp    = {Wed, 25 Jan 2023 11:01:16 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/HeZR014.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@article{vit,
  author       = {Alexey Dosovitskiy and
                  Lucas Beyer and
                  Alexander Kolesnikov and
                  Dirk Weissenborn and
                  Xiaohua Zhai and
                  Thomas Unterthiner and
                  Mostafa Dehghani and
                  Matthias Minderer and
                  Georg Heigold and
                  Sylvain Gelly and
                  Jakob Uszkoreit and
                  Neil Houlsby},
  title        = {An Image is Worth 16x16 Words: Transformers for Image Recognition
                  at Scale},
  journal      = {CoRR},
  volume       = {abs/2010.11929},
  year         = {2020},
  url          = {https://arxiv.org/abs/2010.11929},
  eprinttype    = {arXiv},
  eprint       = {2010.11929},
  timestamp    = {Fri, 20 Nov 2020 14:04:05 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-11929.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}


@article{transformers,
  author       = {Ashish Vaswani and
                  Noam Shazeer and
                  Niki Parmar and
                  Jakob Uszkoreit and
                  Llion Jones and
                  Aidan N. Gomez and
                  Lukasz Kaiser and
                  Illia Polosukhin},
  title        = {Attention Is All You Need},
  journal      = {CoRR},
  volume       = {abs/1706.03762},
  year         = {2017},
  url          = {http://arxiv.org/abs/1706.03762},
  eprinttype    = {arXiv},
  eprint       = {1706.03762},
  timestamp    = {Sat, 23 Jan 2021 01:20:40 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/VaswaniSPUJGKP17.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{scenic,
    author    = {Dehghani, Mostafa and Gritsenko, Alexey and Arnab, Anurag and Minderer, Matthias and Tay, Yi},
    title     = {Scenic: A JAX Library for Computer Vision Research and Beyond},
    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},
    year      = {2022},
    pages     = {21393-21398}
}

@article{OpenImages,
  title={OpenImages: A public dataset for large-scale multi-label and multi-class image classification.},
  author={Krasin, Ivan and Duerig, Tom and Alldrin, Neil and Ferrari, Vittorio and Abu-El-Haija, Sami and Kuznetsova, Alina and Rom, Hassan and Uijlings, Jasper and Popov, Stefan and Kamali, Shahab and Malloci, Matteo and Pont-Tuset, Jordi and Veit, Andreas and Belongie, Serge and Gomes, Victor and Gupta, Abhinav and Sun, Chen and Chechik, Gal and Cai, David and Feng, Zheyun and Narayanan, Dhyanesh and Murphy, Kevin},
  journal={Dataset available from https://storage.googleapis.com/openimages/web/index.html},
  year={2017}
}

@article{ImageNet,
  author       = {Olga Russakovsky and
                  Jia Deng and
                  Hao Su and
                  Jonathan Krause and
                  Sanjeev Satheesh and
                  Sean Ma and
                  Zhiheng Huang and
                  Andrej Karpathy and
                  Aditya Khosla and
                  Michael S. Bernstein and
                  Alexander C. Berg and
                  Li Fei{-}Fei},
  title        = {ImageNet Large Scale Visual Recognition Challenge},
  journal      = {CoRR},
  volume       = {abs/1409.0575},
  year         = {2014},
  url          = {http://arxiv.org/abs/1409.0575},
  eprinttype    = {arXiv},
  eprint       = {1409.0575},
  timestamp    = {Tue, 10 Jan 2023 08:57:21 +0100},
  biburl       = {https://dblp.org/rec/journals/corr/RussakovskyDSKSMHKKBBF14.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{OxfordPets,
  author       = "Omkar M. Parkhi and Andrea Vedaldi and Andrew Zisserman and C. V. Jawahar",
  title        = "Cats and Dogs",
  booktitle    = "IEEE Conference on Computer Vision and Pattern Recognition",
  year         = "2012",
}

@article{Gundetection,
title = {Automatic handgun detection alarm in videos using deep learning},
journal = {Neurocomputing},
volume = {275},
pages = {66-72},
year = {2018},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2017.05.012},
url = {https://www.sciencedirect.com/science/article/pii/S0925231217308196},
author = {Roberto Olmos and Siham Tabik and Francisco Herrera},
keywords = {Classification, Detection, Deep learning, Convolutional Neural Networks, Faster R-CNN, VGG-16, Alarm Activation Time per Interval},
abstract = {Current surveillance and control systems still require human supervision and intervention. This work presents a novel automatic handgun detection system in videos appropriate for both, surveillance and control purposes. We reformulate this detection problem into the problem of minimizing false positives and solve it by i) building the key training data-set guided by the results of a deep Convolutional Neural Networks (CNN) classifier and ii) assessing the best classification model under two approaches, the sliding window approach and region proposal approach. The most promising results are obtained by Faster R-CNN based model trained on our new database. The best detector shows a high potential even in low quality youtube videos and provides satisfactory results as automatic alarm system. Among 30 scenes, it successfully activates the alarm after five successive true positives in a time interval smaller than 0.2 s, in 27 scenes. We also define a new metric, Alarm Activation Time per Interval (AATpI), to assess the performance of a detection model as an automatic detection system in videos.}
}

@article{PASCALVOC,
  added-at = {2020-05-23T11:30:44.000+0200},
  author = {Everingham, Mark and Gool, Luc Van and Williams, Christopher K. I. and Winn, John M. and Zisserman, Andrew},
  biburl = {https://www.bibsonomy.org/bibtex/2cb5ac4f22faf09897fd86076931d682b/jan.hofmann1},
  ee = {https://www.wikidata.org/entity/Q56594395},
  interhash = {8d7846ab0aa897ffead1e7abf2dfba3e},
  intrahash = {cb5ac4f22faf09897fd86076931d682b},
  journal = {Int. J. Comput. Vis.},
  keywords = {thema:pyramid_scene_parsing},
  number = 2,
  pages = {303-338},
  timestamp = {2020-05-23T11:30:44.000+0200},
  title = {The Pascal Visual Object Classes (VOC) Challenge.},
  url = {http://dblp.uni-trier.de/db/journals/ijcv/ijcv88.html#EveringhamGWWZ10},
  volume = 88,
  year = 2010
}

@misc{brambox,
  title = {Basic Requisites for Algorithms on iMages toolBOX},
  howpublished = {\url{https://eavise.gitlab.io/brambox/}},
  note = {Accessed: 2023-08-19}
}